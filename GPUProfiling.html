
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>GPU profiling &#8212; Caliper 2.9.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="OpenMP profiling" href="OpenMP.html" />
    <link rel="prev" title="Caliper Basics" href="CaliperBasics.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="OpenMP.html" title="OpenMP profiling"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="CaliperBasics.html" title="Caliper Basics"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Caliper 2.9.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">GPU profiling</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="gpu-profiling">
<h1>GPU profiling<a class="headerlink" href="#gpu-profiling" title="Permalink to this heading">¶</a></h1>
<p>Caliper can profile CUDA and ROCm API functions and device-side activities like
kernel executions and memory copies. This requires Caliper to be built with
CUpti support (<cite>-DWITH_CUPTI=On</cite>, for CUDA devices) or roctracer support
(<cite>-DWITH_ROCTRACER=On</cite>, for AMD devices).</p>
<section id="profiling-host-side-api-functions">
<h2>Profiling host-side API functions<a class="headerlink" href="#profiling-host-side-api-functions" title="Permalink to this heading">¶</a></h2>
<p>Use the <cite>profile.cuda</cite> or <cite>profile.hip</cite> options to report the time spent in
host-side CUDA and HIP API functions, respectively.
They are available for many ConfigManager configs like
<cite>runtime-report</cite>, <cite>hatchet-region-profile</cite>, and <cite>spot</cite>. They intercept host-side
CUDA API functions like <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> and <code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code>.
The example below shows <cite>runtime-report</cite> output with the <cite>profile.cuda</cite> option
enabled. We can see the time spent in CUDA functions like <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> and
<code class="docutils literal notranslate"><span class="pre">cudaLaunchKernel</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ CALI_CONFIG=runtime-report,profile.cuda lrun -n 4 ./tea_leaf
Path                        Min time/rank Max time/rank Avg time/rank Time %
timestep_loop                    0.000175      0.000791      0.000345  0.002076
  summary                        0.000129      0.000153      0.000140  0.000846
    cudaMemcpy                   0.000414      0.000422      0.000418  0.002516
    cudaLaunchKernel             0.000247      0.000273      0.000256  0.001542
  total_solve                    0.000105      0.000689      0.000252  0.001516
    reset                        0.000160      0.000179      0.000169  0.001021
      internal_halo_update       0.000027      0.000029      0.000028  0.000167
      halo_update                0.000028      0.000031      0.000029  0.000176
      halo_exchange              0.000496      0.000812      0.000607  0.003654
        cudaMemcpy               0.001766      0.001792      0.001779  0.010713
        cudaLaunchKernel         0.000418      0.000450      0.000430  0.002588
      cudaLaunchKernel           0.000097      0.000126      0.000106  0.000640
...
</pre></div>
</div>
</section>
<section id="profiling-device-side-activities">
<h2>Profiling device-side activities<a class="headerlink" href="#profiling-device-side-activities" title="Permalink to this heading">¶</a></h2>
<p>Use the <cite>cuda.gputime</cite> (for NVidia) or <cite>rocm.gputime</cite> (for AMD) options to measure
and report times spent in GPU activities, such as kernels or memory copies:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">CALI_CONFIG</span><span class="o">=</span><span class="n">runtime</span><span class="o">-</span><span class="n">report</span><span class="p">,</span><span class="n">cuda</span><span class="o">.</span><span class="n">gputime</span> <span class="n">lrun</span> <span class="o">-</span><span class="n">n</span> <span class="mi">4</span> <span class="o">./</span><span class="n">tea_leaf</span>
<span class="n">Path</span>                       <span class="n">Min</span> <span class="n">time</span><span class="o">/</span><span class="n">rank</span> <span class="n">Max</span> <span class="n">time</span><span class="o">/</span><span class="n">rank</span> <span class="n">Avg</span> <span class="n">time</span><span class="o">/</span><span class="n">rank</span> <span class="n">Time</span> <span class="o">%</span>    <span class="n">Avg</span> <span class="n">GPU</span> <span class="n">Time</span><span class="o">/</span><span class="n">rank</span> <span class="n">Min</span> <span class="n">GPU</span> <span class="n">Time</span><span class="o">/</span><span class="n">rank</span> <span class="n">Max</span> <span class="n">GPU</span> <span class="n">Time</span><span class="o">/</span><span class="n">rank</span>
<span class="n">timestep_loop</span>                  <span class="mf">16.400791</span>     <span class="mf">16.402930</span>     <span class="mf">16.401392</span> <span class="mf">99.340451</span>         <span class="mf">12.014107</span>         <span class="mf">11.990568</span>         <span class="mf">12.031210</span>
  <span class="n">summary</span>                       <span class="mf">0.000743</span>      <span class="mf">0.000852</span>      <span class="mf">0.000772</span>  <span class="mf">0.004679</span>          <span class="mf">0.000420</span>          <span class="mf">0.000419</span>          <span class="mf">0.000421</span>
  <span class="n">total_solve</span>                  <span class="mf">16.397178</span>     <span class="mf">16.398656</span>     <span class="mf">16.398176</span> <span class="mf">99.320973</span>         <span class="mf">12.013687</span>         <span class="mf">11.990149</span>         <span class="mf">12.030790</span>
    <span class="n">reset</span>                       <span class="mf">0.002924</span>      <span class="mf">0.004401</span>      <span class="mf">0.003682</span>  <span class="mf">0.022303</span>          <span class="mf">0.001463</span>          <span class="mf">0.001461</span>          <span class="mf">0.001465</span>
      <span class="n">internal_halo_update</span>      <span class="mf">0.000031</span>      <span class="mf">0.000038</span>      <span class="mf">0.000033</span>  <span class="mf">0.000201</span>
      <span class="n">halo_update</span>               <span class="mf">0.000033</span>      <span class="mf">0.000042</span>      <span class="mf">0.000036</span>  <span class="mf">0.000220</span>
      <span class="n">halo_exchange</span>             <span class="mf">0.002589</span>      <span class="mf">0.004060</span>      <span class="mf">0.003304</span>  <span class="mf">0.020013</span>          <span class="mf">0.000223</span>          <span class="mf">0.000222</span>          <span class="mf">0.000223</span>
    <span class="n">solve</span>                      <span class="mf">16.377495</span>     <span class="mf">16.377513</span>     <span class="mf">16.377504</span> <span class="mf">99.195768</span>         <span class="mf">12.003737</span>         <span class="mf">11.980207</span>         <span class="mf">12.020827</span>
      <span class="n">dot_product</span>               <span class="mf">0.001003</span>      <span class="mf">0.001339</span>      <span class="mf">0.001151</span>  <span class="mf">0.006971</span>
      <span class="n">internal_halo_update</span>      <span class="mf">0.087994</span>      <span class="mf">0.094034</span>      <span class="mf">0.089777</span>  <span class="mf">0.543764</span>
      <span class="n">halo_update</span>               <span class="mf">0.199130</span>      <span class="mf">0.199757</span>      <span class="mf">0.199502</span>  <span class="mf">1.208347</span>
      <span class="n">halo_exchange</span>            <span class="mf">14.407030</span>     <span class="mf">14.427922</span>     <span class="mf">14.419671</span> <span class="mf">87.337501</span>          <span class="mf">0.624949</span>          <span class="mf">0.619820</span>          <span class="mf">0.629013</span>
  <span class="n">tea_init</span>                      <span class="mf">0.016205</span>      <span class="mf">0.016616</span>      <span class="mf">0.016506</span>  <span class="mf">0.099973</span>          <span class="mf">0.008487</span>          <span class="mf">0.008475</span>          <span class="mf">0.008501</span>
    <span class="n">internal_halo_update</span>        <span class="mf">0.000096</span>      <span class="mf">0.000102</span>      <span class="mf">0.000100</span>  <span class="mf">0.000603</span>
    <span class="n">halo_update</span>                 <span class="mf">0.000104</span>      <span class="mf">0.000113</span>      <span class="mf">0.000109</span>  <span class="mf">0.000660</span>
    <span class="n">halo_exchange</span>               <span class="mf">0.009489</span>      <span class="mf">0.010272</span>      <span class="mf">0.009914</span>  <span class="mf">0.060046</span>          <span class="mf">0.001013</span>          <span class="mf">0.001007</span>          <span class="mf">0.001022</span>
  <span class="n">timestep</span>                      <span class="mf">0.000311</span>      <span class="mf">0.002516</span>      <span class="mf">0.001355</span>  <span class="mf">0.008205</span>
</pre></div>
</div>
<p>The GPU Time/rank metrics denote the number of seconds spent in GPU activities,
such as kernel execution or memory copies. The GPU time values are inclusive,
i.e. they represent the total amount of GPU time launched from a Caliper region
and any region below. Thus, the GPU time values for “timestep_loop” in the
example above represent the GPU activity time for the entire program.</p>
<p>Note that the <cite>cuda.gputime</cite> and <cite>rocm.gputime</cite> options are more expensive than
regular host-side region profiling because they use tracing APIs to record each
GPU activity.
They are primarily intended for short, dedicated performance profiling experiments.</p>
<p>There are also dedicated configs for examining GPU activities:
the <cite>cuda-activity-report</cite>, <cite>cuda-activity-profile</cite>, <cite>rocm-activity-report</cite>, and
<cite>rocm-activity-profile</cite> configs record the time
spent in CUDA activities (e.g. kernel executions or memory copies) on the
device. The GPU times are mapped to the Caliper regions that launched those
GPU activities. The <cite>…-report</cite> options print a human-readable table, while the
<cite>…-profile</cite> options write a machine-readable .json or .cali file.
Here is example output for <cite>cuda-activity-report</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ CALI_CONFIG=cuda-activity-report lrun -n 4 ./tea_leaf
Path                        Avg Host Time Max Host Time Avg GPU Time Max GPU Time GPU %
timestep_loop                   17.052183     17.053008    12.020218    12.037409   70.490786
  total_solve                   17.048899     17.049464    12.019799    12.036989   70.501909
    solve                       17.026991     17.027000    12.009868    12.027047   70.534294
      dot_product                0.004557      0.006057
      cudaMalloc                 0.000050      0.000055
      internal_halo_update       0.051974      0.052401
      halo_update                0.110023      0.111015
      halo_exchange             15.154157     15.184635     0.621857     0.625657    4.103542
        cudaMemcpy              12.398854     12.422384     0.234947     0.235587    1.894913
        cudaLaunchKernel         1.426069      1.440035     0.386910     0.390767   27.131206
      cudaMemcpy                 0.497959      0.503879     0.003377     0.003433    0.678115
      cudaLaunchKernel           0.772027      0.793401    11.384634    11.402917 1474.641141
</pre></div>
</div>
<p>For each Caliper region, we now see the time spent on the CPU (“Avg/Max Host
Time”) and the aggregate time on the GPU for activities launched from
this region (“Avg/Max GPU Time”). Note how the <code class="docutils literal notranslate"><span class="pre">cudaLaunchKernel</span></code> call in
the last row of the output has ~0.78 seconds of CPU time associated with it,
but ~11.38 seconds of GPU time - these 11.38 seconds reflect the amount of GPU
activities launched asynchronously from this region. Most CPU time in the
example output is actually spent in <code class="docutils literal notranslate"><span class="pre">cudaMemcpy</span></code> under <code class="docutils literal notranslate"><span class="pre">halo_exchange</span></code>
- we can deduce that much of this is actually synchronization time spent
waiting until the GPU kernels are complete.</p>
<p>The “GPU %” metric shows the fraction of (wall-clock) CPU time in which there
are GPU activities, and represents GPU utilization inside a Caliper region.
The percentage is based on the total inclusive CPU time and GPU activities for
the region and it sub-regions. The “GPU %” for the top-level region
(<code class="docutils literal notranslate"><span class="pre">timestep_loop</span></code>) represents the GPU utilization of the entire program.</p>
<p>The definition of the reported metrics is as follows:</p>
<dl class="simple">
<dt>Avg Host Time</dt><dd><p>Inclusive time (seconds) in the Caliper region on the Host (CPU).
Typically the wall-clock time. Average value across MPI ranks.</p>
</dd>
<dt>Max Host Time</dt><dd><p>Inclusive time (seconds) in the Caliper region on the Host (CPU).
Typically the wall-clock time. Maximum value among all MPI ranks.</p>
</dd>
<dt>Avg GPU Time</dt><dd><p>Inclusive total time (seconds) of activities executing on the GPU
launched from the Caliper region. Average across MPI ranks.</p>
</dd>
<dt>Max GPU Time</dt><dd><p>Inclusive total time (seconds) of activities executing on the GPU
launched from the Caliper region. Maximum value among all MPI ranks.</p>
</dd>
<dt>GPU %</dt><dd><p>Fraction of total inclusive GPU time vs. CPU time. Typically
represents the GPU utilization in the Caliper region.</p>
</dd>
</dl>
</section>
<section id="show-gpu-kernels">
<h2>Show GPU kernels<a class="headerlink" href="#show-gpu-kernels" title="Permalink to this heading">¶</a></h2>
<p>Use the <cite>show_kernels</cite> option in <cite>cuda-activity-report</cite> to distinguish
individual CUDA kernels:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> $ CALI_CONFIG=cuda-activity-report,show_kernels lrun -n 4 ./tea_leaf
 Path                        Kernel                                           Avg Host Time Max Host Time Avg GPU Time Max GPU Time GPU %
 timestep_loop
  |-                                                                              17.068956     17.069917     0.239392     0.240725 1.402501
  |-                         device_unpack_top_buffe~~le*, double*, int, int)                                 0.091051     0.092734
  |-                         device_tea_leaf_ppcg_so~~ const*, double const*)                                 5.409844     5.419096
  |-                         device_tea_leaf_ppcg_so~~t*, double const*, int)                                 5.316101     5.320777
  |-                         device_pack_right_buffe~~le*, double*, int, int)                                 0.112455     0.113198
  |-                         device_pack_top_buffer(~~le*, double*, int, int)                                 0.092634     0.092820
(...)
  |-                         device_pack_bottom_buff~~le*, double*, int, int)                                 0.098929     0.099095
   summary
    |-                                                                             0.000881      0.000964     0.000010     0.000011 1.179024
    |-                       device_field_summary_ke~~ble*, double*, double*)                                 0.000325     0.000326
    |-                       void reduction&lt;double, ~~N_TYPE)0&gt;(int, double*)                                 0.000083     0.000084
     cudaMemcpy                                                                    0.000437      0.000457     0.000010     0.000011 2.376874
     cudaLaunchKernel
      |-                                                                           0.000324      0.000392
      |-                     device_field_summary_ke~~ble*, double*, double*)                                 0.000325     0.000326
      |-                     void reduction&lt;double, ~~N_TYPE)0&gt;(int, double*)                                 0.000083     0.000084
</pre></div>
</div>
<p>We now see the GPU time in each kernel. The display is “inclusive”, that is,
for each Caliper region, we see kernels launched from this region as well as
all regions below it. Under the top-level region (<code class="docutils literal notranslate"><span class="pre">timestep_loop</span></code>),
we see the total time spent in each CUDA kernel in the program.</p>
</section>
<section id="profiling-memory-copies">
<h2>Profiling memory copies<a class="headerlink" href="#profiling-memory-copies" title="Permalink to this heading">¶</a></h2>
<p>The <cite>cuda.memcpy</cite> option shows the amount of data copied between CPU and GPU
memory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ CALI_CONFIG=cuda-activity-report,cuda.memcpy lrun -n 4 ./tea_leaf
Path                        Avg Host Time Max Host Time Avg GPU Time Max GPU Time GPU %       Copy CPU-&gt;GPU (avg) Copy CPU-&gt;GPU (max) Copy GPU-&gt;CPU (avg) Copy GPU-&gt;CPU (max)
timestep_loop                   17.098644     17.100283    12.020492    12.040316   70.300846
  total_solve                   17.094882     17.095510    12.020072    12.039896   70.313864
    solve                       17.072250     17.072253    12.010138    12.029962   70.348891
      dot_product                0.001489      0.001684
      cudaMalloc                 0.000050      0.000054
      internal_halo_update       0.052739      0.053484
      halo_update                0.110009      0.111008
      halo_exchange             15.194774     15.220273     0.622893     0.629519    4.099388
        cudaMemcpy              12.405958     12.430534     0.234917     0.235315    1.893578          902.517616          902.517616          902.469568          902.469568
        cudaLaunchKernel         1.431387      1.463419     0.387976     0.394445   27.104925
      cudaMemcpy                 0.493047      0.494699     0.003369     0.003393    0.683394            0.040320            0.040320            0.019232            0.019232
</pre></div>
</div>
<p>In the example, there were about 902 Megabytes copied from CPU to GPU memory
and back. There are four new metrics:</p>
<dl class="simple">
<dt>Copy CPU-&gt;GPU (avg)</dt><dd><p>Data copied (Megabytes) from CPU to GPU memory. Average across MPI ranks.</p>
</dd>
<dt>Copy CPU-&gt;GPU (max)</dt><dd><p>Data copied (Megabytes) from CPU to GPU memory. Maximum among MPI ranks.</p>
</dd>
<dt>Copy GPU-&gt;CPU (avg)</dt><dd><p>Data copied (Megabytes) from GPU to CPU memory. Average across MPI ranks.</p>
</dd>
<dt>Copy GPU-&gt;CPU (max)</dt><dd><p>Data copied (Megabytes) from GPU to CPU memory. Maximum among MPI ranks.</p>
</dd>
</dl>
</section>
<section id="profiles-in-json-or-cali-format">
<h2>Profiles in JSON or CALI format<a class="headerlink" href="#profiles-in-json-or-cali-format" title="Permalink to this heading">¶</a></h2>
<p>The <cite>cuda-activity-profile</cite> and <cite>rocm-activity-profile</cite> configs record GPU
activities data similar to the corresponding <cite>…-report</cite> options, but write
it in machine-readable JSON or Caliper’s “.cali” format for processing with
<cite>cali-query</cite>. By default, it writes the <cite>json-split</cite> format that can be read
by Hatchet:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ CALI_CONFIG=cuda-activity-profile lrun -n 4 ./tea_leaf
$ ls *.json
cuda_profile.json
</pre></div>
</div>
<p>Other formats can be selected with the <cite>output.format</cite> option. Possible
values:</p>
<dl class="simple">
<dt>cali</dt><dd><p>The Caliper profile/trace format for processing with <cite>cali-query</cite>.</p>
</dd>
<dt>hatchet</dt><dd><p>JSON format readable by Hatchet. See <a class="reference internal" href="OutputFormats.html#json-split-format"><span class="std std-ref">Json-split</span></a>.</p>
</dd>
<dt>json</dt><dd><p>Easy-to-parse list-of-dicts style JSON. See <a class="reference internal" href="OutputFormats.html#json-format"><span class="std std-ref">Json</span></a>.</p>
</dd>
</dl>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/caliper-logo-small.png" alt="Logo"/>
            </a></p>
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">GPU profiling</a><ul>
<li><a class="reference internal" href="#profiling-host-side-api-functions">Profiling host-side API functions</a></li>
<li><a class="reference internal" href="#profiling-device-side-activities">Profiling device-side activities</a></li>
<li><a class="reference internal" href="#show-gpu-kernels">Show GPU kernels</a></li>
<li><a class="reference internal" href="#profiling-memory-copies">Profiling memory copies</a></li>
<li><a class="reference internal" href="#profiles-in-json-or-cali-format">Profiles in JSON or CALI format</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="CaliperBasics.html"
                          title="previous chapter">Caliper Basics</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="OpenMP.html"
                          title="next chapter">OpenMP profiling</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/GPUProfiling.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="OpenMP.html" title="OpenMP profiling"
             >next</a> |</li>
        <li class="right" >
          <a href="CaliperBasics.html" title="Caliper Basics"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Caliper 2.9.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">GPU profiling</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2015-2021, Lawrence Livermore National Laboratory.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.1.1.
    </div>
  </body>
</html>